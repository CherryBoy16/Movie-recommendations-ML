# -*- coding: utf-8 -*-
"""ET-8_Ad projec-MRS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18snkU7-XbrTpR-72rmyxwtrMAr2-LVHQ
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
df = pd.read_excel("movie_recommendation_dataset.xlsx")

df.info()
df.head()

df.isnull().sum()

df.describe()

"""**HISTPLOT**"""

#Histplot
plt.figure(figsize=(8, 4))
sns.histplot(df["rating"], bins=10, kde=True)
plt.title("Distribution of Ratings")
plt.xlabel("Rating")
plt.ylabel("Count")
plt.show()

"""**BARPLOT**"""

#Barplot
top_movies = df.groupby("movie")["popularity_score"].mean().sort_values(ascending=False).head(10)
plt.figure(figsize=(10, 5))
sns.barplot(x=top_movies.values, y=top_movies.index)
plt.title("Top 10 Most Popular Movies")
plt.xlabel("Popularity Score")
plt.ylabel("Movie")
plt.show()

#Checking correlation as the titles are in the string format we here take the number feature
numeric_df = df.select_dtypes(include=['number'])
correlation_matrix = numeric_df.corr()

"""**HEATMAP**"""

plt.figure(figsize=(10, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Feature Correlation Heatmap")
plt.show()

"""**HISTPLOT**"""

plt.figure(figsize=(8, 5))
sns.histplot(df['rating'], bins=5, kde=True, color="blue")
plt.title("User Rating Distribution")
plt.xlabel("Rating")
plt.ylabel("Count")
plt.show()

"""**SCATTERPLOT**"""

plt.figure(figsize=(10, 5))
sns.scatterplot(x=df['popularity_score'], y=df['rating'], alpha=0.5)
plt.title("Popularity Score vs. Movie Ratings")
plt.xlabel("Popularity Score")
plt.ylabel("Average Rating")
plt.show()

"""**PREPROCESSING**"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

df = df.dropna()

features = ["price", "popularity_score", "session_duration", "discount_applied", "user_age", "previous_purchases"]
target = "rating"
X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)

regressor = LinearRegression()
regressor.fit(X_train, y_train)
y_pred = regressor.predict(X_test)
print("Regression Coefficients:", regressor.coef_)
print("Intercept:", regressor.intercept_)

# Calculating MSE, MAE, RMSE
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mse)
print(f"Mean Squared Error (MSE): {mse}")
print(f"Mean Absolute Error (MAE): {mae}")
print(f"Root Mean Squared Error (RMSE): {rmse}")

# Converting timestamp to datetime
df["timestamp"] = pd.to_datetime(df["timestamp"], unit="s")
df["popularity_score"] = df["popularity_score"] / df["popularity_score"].max()
df["user_id"] = df["user_id"].astype(str)
df["item_id"] = df["item_id"].astype(str)
print("Preprocessing Complete!")

import numpy as np
ratings_matrix = df.pivot_table(index='user_id', columns='item_id', values='rating')
def recommend_movies(user_id, num_recommendations=5):
    if user_id not in ratings_matrix.index:
        return ["User not found"]
    user_ratings = ratings_matrix.loc[user_id]
    similarity = ratings_matrix.corrwith(user_ratings, method='pearson', axis=1)
    similarity = similarity.drop(user_id).dropna().sort_values(ascending=False)
    similar_users = similarity.index[:5]
    recommended_movies = df[df["user_id"].isin(similar_users) & df["item_id"].isin(user_ratings[user_ratings.isna()].index)]
    top_movies = recommended_movies.groupby("movie")["rating"].mean().sort_values(ascending=False).head(num_recommendations)
    return top_movies.index.tolist()
recommend_movies(24789)

"""**DECISION TREE**"""

import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.tree import plot_tree

model = LinearRegression()
model.fit(X_train, y_train)
preds = model.predict(X_test)
np.mean((preds-y_test)**2)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
filename = r'movie_recommendation_dataset.xlsx'
dataframe = pd.read_excel(filename)
if 'timestamp' in dataframe.columns:
    dataframe.drop(columns=['timestamp'], inplace=True)
for col in dataframe.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    dataframe[col] = le.fit_transform(dataframe[col])
X = dataframe.iloc[:, :-1]
y = dataframe.iloc[:, -1].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=10)

model = DecisionTreeRegressor(random_state=40,max_depth=2)
model.fit(X_train, y_train)
plt.figure(figsize=(15, 8))
plot_tree(model, filled=True, feature_names=X.columns)
plt.show()

print("y_true:", y_test)
print("y_pred:", y_pred)

"""**FEATURE ENGINEERING**"""

import pandas as pd
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.preprocessing import LabelEncoder
data = pd.read_excel("movie_recommendation_dataset.xlsx")
X = data.drop(columns=["popularity_score"])
y = data["rating"]
X = X.apply(lambda col: LabelEncoder().fit_transform(col) if col.dtype == "object" else col)
if y.dtype == "object":
    y = LabelEncoder().fit_transform(y)
selector = SelectKBest(score_func=f_classif, k=2)
X_new = selector.fit_transform(X, y)
print("Feature Scores:", selector.scores_)
print("Selected Features:", selector.get_support())

"""**BAGGING REGRESSOR**"""

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold, cross_val_score
from sklearn.ensemble import BaggingRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder
filename = r'movie_recommendation_dataset.xlsx'
dataframe = pd.read_excel(filename)
if 'timestamp' in dataframe.columns:
    dataframe.drop(columns=['timestamp'], inplace=True)
for col in dataframe.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    dataframe[col] = le.fit_transform(dataframe[col])
dataframe = dataframe.sample(frac=0.5, random_state=7)
X = dataframe.iloc[:, :-1].values
y = dataframe.iloc[:, -1].values
seed = 7
kfold = KFold(n_splits=5, shuffle=True, random_state=seed)
cart = DecisionTreeRegressor(max_depth=10)
num_trees = 50
model = BaggingRegressor(estimator=cart, n_estimators=num_trees, random_state=seed, n_jobs=-1)
results = cross_val_score(model, X, y, cv=kfold)
print(results.mean())

"""**RANDOM FOREST REGRESSOR**"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import KFold, cross_val_score
num_trees = 100
max_features = 3
kfold = KFold(n_splits=10, shuffle=True, random_state=7)
model = RandomForestRegressor(n_estimators=num_trees, max_features=max_features)
results = cross_val_score(model, X, y, cv=kfold)
print(results.mean())

"""**XG-BOOST REGRESSOR**"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from numpy import loadtxt
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

filename = 'movie_recommendation_dataset.xlsx'
data = pd.read_excel(filename)
for col in data.select_dtypes(include=['object']).columns:  # Select categorical columns
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col])
X = data.iloc[:, 0:8].values
y = data.iloc[:, 8].values
seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)
model = XGBRegressor()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
print(f"Mean Squared Error (MSE): {mse:.4f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")

"""**ACCURACY AMONG ALL REGRESSION MODELS**"""

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, BaggingRegressor
from sklearn.tree import DecisionTreeRegressor
models = {
    "Decision Tree": DecisionTreeRegressor(max_depth=10),
    "Bagging Regressor": BaggingRegressor(DecisionTreeRegressor(max_depth=10), n_estimators=50, random_state=42),
    "AdaBoost Regressor": AdaBoostRegressor(DecisionTreeRegressor(max_depth=4), n_estimators=50, random_state=42),
    "Random Forest Regressor": RandomForestRegressor(n_estimators=100, random_state=42)
}
for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=5, scoring='r2')
    print(f"{name}: Mean R2-Score = {scores.mean():.4f}")

import pickle
with open('movie_recommendation.pkl','wb') as f:
  pickle.dump(model,f)
print("Model has been saved as 'movie_recommendation.pkl'")

import os
print(os.path.exists("movie_recommendation.pkl"))

from google.colab import files
files.download("movie_recommendation.pkl")

